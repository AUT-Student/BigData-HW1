{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData_HW1_Q3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsaG0x1zt9nNFmTb3rZbgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/BigData-HW1/blob/main/BigData_HW1_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "1VdxSswtjDwZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvITWqbegxZU"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id='1-OCBGBtKoY_PadKHcXDyWxHQ2BS8Nulo'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('hw1.zip')\n",
        "\n",
        "!unzip hw1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSH"
      ],
      "metadata": {
        "id": "kf6js6-Z0t5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: Jessica Su, Wanzi Zhou, Pratyaksh Sharma, Dylan Liu, Ansh Shukla\n",
        "#Modified: Alex Porter\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import unittest\n",
        "from PIL import Image\n",
        "\n",
        "# Finds the L1 distance between two vectors\n",
        "# u and v are 1-dimensional np.array objects\n",
        "# TODO: Implement this\n",
        "def l1(u, v):\n",
        "    raise NotImplementedError\n",
        "\n",
        "# Loads the data into a np array, where each row corresponds to\n",
        "# an image patch -- this step is sort of slow.\n",
        "# Each row in the data is an image, and there are 400 columns.\n",
        "def load_data(filename):\n",
        "    return np.genfromtxt(filename, delimiter=',')\n",
        "\n",
        "# Creates a hash function from a list of dimensions and thresholds.\n",
        "def create_function(dimensions, thresholds):\n",
        "    def f(v):\n",
        "        boolarray = [v[dimensions[i]] >= thresholds[i] for i in range(len(dimensions))]\n",
        "        return \"\".join(map(str, map(int, boolarray)))\n",
        "    return f\n",
        "\n",
        "# Creates the LSH functions (functions that compute L K-bit hash keys).\n",
        "# Each function selects k dimensions (i.e. column indices of the image matrix)\n",
        "# at random, and then chooses a random threshold for each dimension, between 0 and\n",
        "# 255.  For any image, if its value on a given dimension is greater than or equal to\n",
        "# the randomly chosen threshold, we set that bit to 1.  Each hash function returns\n",
        "# a length-k bit string of the form \"0101010001101001...\", and the L hash functions \n",
        "# will produce L such bit strings for each image.\n",
        "def create_functions(k, L, num_dimensions=400, min_threshold=0, max_threshold=255):\n",
        "    functions = []\n",
        "    for i in range(L):\n",
        "        dimensions = np.random.randint(low = 0, \n",
        "                                   high = num_dimensions,\n",
        "                                   size = k)\n",
        "        thresholds = np.random.randint(low = min_threshold, \n",
        "                                   high = max_threshold + 1, \n",
        "                                   size = k)\n",
        "\n",
        "        functions.append(create_function(dimensions, thresholds))\n",
        "    return functions\n",
        "\n",
        "# Hashes an individual vector (i.e. image).  This produces an array with L\n",
        "# entries, where each entry is a string of k bits.\n",
        "def hash_vector(functions, v):\n",
        "    return np.array([f(v) for f in functions])\n",
        "\n",
        "# Hashes the data in A, where each row is a datapoint, using the L\n",
        "# functions in \"functions.\"\n",
        "def hash_data(functions, A):\n",
        "    return np.array(list(map(lambda v: hash_vector(functions, v), A)))\n",
        "\n",
        "# Retrieve all of the points that hash to one of the same buckets \n",
        "# as the query point.  Do not do any random sampling (unlike what the first\n",
        "# part of this problem prescribes).\n",
        "# Don't retrieve a point if it is the same point as the query point.\n",
        "def get_candidates(hashed_A, hashed_point, query_index):\n",
        "    return filter(lambda i: i != query_index and \\\n",
        "        any(hashed_point == hashed_A[i]), range(len(hashed_A)))\n",
        "\n",
        "# Sets up the LSH.  You should try to call this function as few times as \n",
        "# possible, since it is expensive.\n",
        "# A: The dataset in which each row is an image patch.\n",
        "# Return the LSH functions and hashed data structure.\n",
        "def lsh_setup(A, k = 24, L = 10):\n",
        "    functions = create_functions(k = k, L = L)\n",
        "    hashed_A = hash_data(functions, A)\n",
        "    return (functions, hashed_A)\n",
        "\n",
        "# Run the entire LSH algorithm\n",
        "def lsh_search(A, hashed_A, functions, query_index, num_neighbors = 10):\n",
        "    hashed_point = hash_vector(functions, A[query_index, :])\n",
        "    candidate_row_nums = get_candidates(hashed_A, hashed_point, query_index)\n",
        "    \n",
        "    distances = map(lambda r: (r, l1(A[r], A[query_index])), candidate_row_nums)\n",
        "    best_neighbors = sorted(distances, key=lambda t: t[1])[:num_neighbors]\n",
        "\n",
        "    return [t[0] for t in best_neighbors]\n",
        "\n",
        "# Plots images at the specified rows and saves them each to files.\n",
        "def plot(A, row_nums, base_filename):\n",
        "    for row_num in row_nums:\n",
        "        patch = np.reshape(A[row_num, :], [20, 20])\n",
        "        im = Image.fromarray(patch)\n",
        "        if im.mode != 'RGB':\n",
        "            im = im.convert('RGB')\n",
        "        im.save(base_filename + \"-\" + str(row_num) + \".png\")\n",
        "\n",
        "# Finds the nearest neighbors to a given vector, using linear search.\n",
        "def linear_search(A, query_index, num_neighbors):\n",
        "    raise NotImplementedError #TODO\n",
        "\n",
        "# TODO: Write a function that computes the error measure\n",
        "\n",
        "# TODO: Solve Problem 3\n",
        "def problem3():\n",
        "    raise NotImplementedError\n",
        "\n",
        "#### TESTS #####\n",
        "\n",
        "class TestLSH(unittest.TestCase):\n",
        "    def test_l1(self):\n",
        "        u = np.array([1, 2, 3, 4])\n",
        "        v = np.array([2, 3, 2, 3])\n",
        "        self.assertEqual(l1(u, v), 4)\n",
        "\n",
        "    def test_hash_data(self):\n",
        "        f1 = lambda v: sum(v)\n",
        "        f2 = lambda v: sum([x * x for x in v])\n",
        "        A = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "        self.assertEqual(f1(A[0,:]), 6)\n",
        "        self.assertEqual(f2(A[0,:]), 14)\n",
        "\n",
        "        functions = [f1, f2]\n",
        "        self.assertTrue(np.array_equal(hash_vector(functions, A[0, :]), np.array([6, 14])))\n",
        "        self.assertTrue(np.array_equal(hash_data(functions, A), np.array([[6, 14], [15, 77]])))\n",
        "\n",
        "    ### TODO: Write your tests here (they won't be graded, \n",
        "    ### but you may find them helpful)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "#    unittest.main() ### TODO: Uncomment this to run tests\n",
        "    problem3()\n"
      ],
      "metadata": {
        "id": "Nvix82Ns3HJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}