{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData_HW1_Q3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO9aF5+Nxu+sQRZJWUjwbud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/BigData-HW1/blob/main/BigData_HW1_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "1VdxSswtjDwZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvITWqbegxZU",
        "outputId": "fa58e6ca-db23-4e46-86d5-0793200f9dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hw1.zip\n",
            "replace hw1-files/q3/patches.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: hw1-files/q3/patches.csv  A\n",
            "\n",
            "  inflating: hw1-files/q3/lsh.py     \n",
            "  inflating: hw1-files/q1/dataset1.txt  \n",
            "  inflating: hw1-files/q2/games_library.txt  \n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id='1-OCBGBtKoY_PadKHcXDyWxHQ2BS8Nulo'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('hw1.zip')\n",
        "\n",
        "!unzip hw1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSH"
      ],
      "metadata": {
        "id": "kf6js6-Z0t5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: Jessica Su, Wanzi Zhou, Pratyaksh Sharma, Dylan Liu, Ansh Shukla\n",
        "#Modified: Alex Porter\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import unittest\n",
        "from PIL import Image\n",
        "\n",
        "# Finds the L1 distance between two vectors\n",
        "# u and v are 1-dimensional np.array objects\n",
        "# Implemented by me!\n",
        "def l1(u, v):\n",
        "    distance = 0\n",
        "    for i in range(len(u)):\n",
        "      distance += np.abs(u[i]-v[i])\n",
        "    return distance\n",
        "\n",
        "# Loads the data into a np array, where each row corresponds to\n",
        "# an image patch -- this step is sort of slow.\n",
        "# Each row in the data is an image, and there are 400 columns.\n",
        "def load_data(filename):\n",
        "    return np.genfromtxt(filename, delimiter=',')\n",
        "\n",
        "# Creates a hash function from a list of dimensions and thresholds.\n",
        "def create_function(dimensions, thresholds):\n",
        "    def f(v):\n",
        "        boolarray = [v[dimensions[i]] >= thresholds[i] for i in range(len(dimensions))]\n",
        "        return \"\".join(map(str, map(int, boolarray)))\n",
        "    return f\n",
        "\n",
        "# Creates the LSH functions (functions that compute L K-bit hash keys).\n",
        "# Each function selects k dimensions (i.e. column indices of the image matrix)\n",
        "# at random, and then chooses a random threshold for each dimension, between 0 and\n",
        "# 255.  For any image, if its value on a given dimension is greater than or equal to\n",
        "# the randomly chosen threshold, we set that bit to 1.  Each hash function returns\n",
        "# a length-k bit string of the form \"0101010001101001...\", and the L hash functions \n",
        "# will produce L such bit strings for each image.\n",
        "def create_functions(k, L, num_dimensions=400, min_threshold=0, max_threshold=255):\n",
        "    functions = []\n",
        "    for i in range(L):\n",
        "        dimensions = np.random.randint(low = 0, \n",
        "                                   high = num_dimensions,\n",
        "                                   size = k)\n",
        "        thresholds = np.random.randint(low = min_threshold, \n",
        "                                   high = max_threshold + 1, \n",
        "                                   size = k)\n",
        "\n",
        "        functions.append(create_function(dimensions, thresholds))\n",
        "    return functions\n",
        "\n",
        "# Hashes an individual vector (i.e. image).  This produces an array with L\n",
        "# entries, where each entry is a string of k bits.\n",
        "def hash_vector(functions, v):\n",
        "    return np.array([f(v) for f in functions])\n",
        "\n",
        "# Hashes the data in A, where each row is a datapoint, using the L\n",
        "# functions in \"functions.\"\n",
        "def hash_data(functions, A):\n",
        "    return np.array(list(map(lambda v: hash_vector(functions, v), A)))\n",
        "\n",
        "# Retrieve all of the points that hash to one of the same buckets \n",
        "# as the query point.  Do not do any random sampling (unlike what the first\n",
        "# part of this problem prescribes).\n",
        "# Don't retrieve a point if it is the same point as the query point.\n",
        "def get_candidates(hashed_A, hashed_point, query_index):\n",
        "    return filter(lambda i: i != query_index and \\\n",
        "        any(hashed_point == hashed_A[i]), range(len(hashed_A)))\n",
        "\n",
        "# Sets up the LSH.  You should try to call this function as few times as \n",
        "# possible, since it is expensive.\n",
        "# A: The dataset in which each row is an image patch.\n",
        "# Return the LSH functions and hashed data structure.\n",
        "def lsh_setup(A, k = 24, L = 10):\n",
        "    functions = create_functions(k = k, L = L)\n",
        "    hashed_A = hash_data(functions, A)\n",
        "    return (functions, hashed_A)\n",
        "\n",
        "# Run the entire LSH algorithm\n",
        "def lsh_search(A, hashed_A, functions, query_index, num_neighbors = 10):\n",
        "    hashed_point = hash_vector(functions, A[query_index, :])\n",
        "    candidate_row_nums = get_candidates(hashed_A, hashed_point, query_index)\n",
        "    \n",
        "    distances = map(lambda r: (r, l1(A[r], A[query_index])), candidate_row_nums)\n",
        "    best_neighbors = sorted(distances, key=lambda t: t[1])[:num_neighbors]\n",
        "\n",
        "    return [t[0] for t in best_neighbors]\n",
        "\n",
        "# Plots images at the specified rows and saves them each to files.\n",
        "def plot(A, row_nums, base_filename):\n",
        "    for row_num in row_nums:\n",
        "        patch = np.reshape(A[row_num, :], [20, 20])\n",
        "        im = Image.fromarray(patch)\n",
        "        if im.mode != 'RGB':\n",
        "            im = im.convert('RGB')\n",
        "        im.save(base_filename + \"-\" + str(row_num) + \".png\")\n",
        "\n",
        "# Finds the nearest neighbors to a given vector, using linear search.\n",
        "# Implemented by me!\n",
        "def linear_search(A, query_index, num_neighbors):\n",
        "    # All rows except query index are condidates! Remain of this function is similar to lsh_search\n",
        "    candidate_row_nums = list(set(range(len(A))) - set([query_index]))\n",
        "    \n",
        "    distances = map(lambda r: (r, l1(A[r], A[query_index])), candidate_row_nums)\n",
        "    best_neighbors = sorted(distances, key=lambda t: t[1])[:num_neighbors]\n",
        "\n",
        "    return [t[0] for t in best_neighbors]\n",
        "\n",
        "# TODO: Write a function that computes the error measure\n",
        "def error():\n",
        "  pass"
      ],
      "metadata": {
        "id": "Nvix82Ns3HJp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### TESTS #####\n",
        "class TestLSH(unittest.TestCase):\n",
        "    def test_l1(self):\n",
        "        u = np.array([1, 2, 3, 4])\n",
        "        v = np.array([2, 3, 2, 3])\n",
        "        self.assertEqual(l1(u, v), 4)\n",
        "\n",
        "    def test_hash_data(self):\n",
        "        f1 = lambda v: sum(v)\n",
        "        f2 = lambda v: sum([x * x for x in v])\n",
        "        A = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "        self.assertEqual(f1(A[0,:]), 6)\n",
        "        self.assertEqual(f2(A[0,:]), 14)\n",
        "\n",
        "        functions = [f1, f2]\n",
        "        self.assertTrue(np.array_equal(hash_vector(functions, A[0, :]), np.array([6, 14])))\n",
        "        self.assertTrue(np.array_equal(hash_data(functions, A), np.array([[6, 14], [15, 77]])))\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJPtVGQm3NG4",
        "outputId": "43b927b4-28b2-4bd9-dfa4-60bd2b74bac0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_hash_data (__main__.TestLSH) ... ok\n",
            "test_l1 (__main__.TestLSH) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.008s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f97a7fd1f90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B (Running Time Expriment)"
      ],
      "metadata": {
        "id": "ev-vdlWNZUbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Load Dataset\n",
        "A = load_data(filename=\"/content/hw1-files/q3/patches.csv\")\n",
        "\n",
        "# LSH Setup\n",
        "start_time = time.time()\n",
        "functions, hashed_A = lsh_setup(A = A, k = 24, L = 10)\n",
        "print(f\"LSH Setup Time =  {time.time() - start_time} seconds\")\n",
        "\n",
        "# Query Index List\n",
        "query_index_list = [100, 199, 300, 399, 500, 599, 700, 799, 900, 999]\n",
        "\n",
        "# LSH Search\n",
        "start_time = time.time()\n",
        "for query_index in  query_index_list:\n",
        "  lsh_best_row_nums = lsh_search(A, hashed_A, functions, query_index, num_neighbors = 3)\n",
        "print(f\"LSH Search Average Time =  {(time.time() - start_time)/len(query_index_list)} seconds\")\n",
        "\n",
        "# Linear Search\n",
        "start_time = time.time()\n",
        "for query_index in  query_index_list:\n",
        "  linear_best_row_nums = linear_search(A, query_index, num_neighbors = 3)\n",
        "print(f\"Linear Search Average Time =  {(time.time() - start_time)/len(query_index_list)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8dS80bF3rR0",
        "outputId": "e528b59e-4907-4388-866e-06a2ed6ff3bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSH Setup Time =  16.979037523269653 seconds\n",
            "LSH Search Average Time =  1.323847723007202 seconds\n",
            "Linear Search Average Time =  34.99098289012909 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part C (Error Expriment)"
      ],
      "metadata": {
        "id": "pLdoo4iRdDVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Aro8PG_sdLhj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}